# ABSA University - Dokploy Environment Variables (Self-Hosted)
# Configurado para: university.grupoabsa.ai
# SIN DEPENDENCIAS DE MANUS - Todo en tu Docker instance

# ============================================
# BASE DE DATOS
# ============================================
DB_ROOT_PASSWORD=absa_root_secure_password_change_me
DB_NAME=absa_lms
DB_USER=absa_user
DB_PASSWORD=absa_user_secure_password_change_me
DB_PORT=3306
DB_HOST=db

# ============================================
# APLICACIÓN
# ============================================
NODE_ENV=production
APP_PORT=8082
APP_DOMAIN=university.grupoabsa.ai

# URL de conexión a base de datos
DATABASE_URL=mysql://absa_user:absa_user_secure_password_change_me@db:3306/absa_lms

# ============================================
# AUTENTICACIÓN JWT
# ============================================
# Genera un JWT_SECRET seguro con: openssl rand -base64 32
JWT_SECRET=your_jwt_secret_key_change_this_in_production

# ============================================
# BRANDING DE LA APLICACIÓN
# ============================================
VITE_APP_TITLE=ABSA UNIVERSITY
VITE_APP_LOGO=/logo-absa.png

# ============================================
# AUTENTICACIÓN LOCAL (Sin Manus OAuth)
# ============================================
# Para usar autenticación local por correo/código sin OAuth de Manus
# Configura estos valores para tu servidor local

# Tipo de autenticación: "local" o "oauth"
AUTH_TYPE=local

# Para autenticación local, estos valores pueden ser vacíos o localhost
VITE_APP_ID=local-app
OAUTH_SERVER_URL=http://localhost:8082
VITE_OAUTH_PORTAL_URL=http://localhost:8082

OWNER_OPEN_ID=admin@absa.edu
OWNER_NAME=ABSA Administrator

# ============================================
# SERVICIOS LOCALES (Sin Manus Forge API)
# ============================================

# === LLM LOCAL (Ollama o LocalAI) ===
# Opción 1: Usar Ollama (recomendado)
# Instala: https://ollama.ai
# Descarga modelo: ollama pull mistral o ollama pull llama2
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=mistral

# Opción 2: Usar LocalAI (alternativa)
# LLM_PROVIDER=localai
# LOCALAI_BASE_URL=http://localai:8080
# LOCALAI_MODEL=gpt-3.5-turbo

# Opción 3: Usar OpenAI (si prefieres)
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-your_openai_api_key_here

# ============================================
# EMBEDDINGS (Para RAG/Qdrant)
# ============================================
# Opción 1: Usar Ollama para embeddings
EMBEDDINGS_PROVIDER=ollama
OLLAMA_EMBEDDINGS_MODEL=nomic-embed-text

# Opción 2: Usar LocalAI para embeddings
# EMBEDDINGS_PROVIDER=localai
# LOCALAI_EMBEDDINGS_MODEL=text-embedding-ada-002

# Opción 3: Usar OpenAI
# EMBEDDINGS_PROVIDER=openai
# OPENAI_API_KEY=sk-your_openai_api_key_here

# ============================================
# QDRANT - Vector Database para RAG
# ============================================
# Qdrant se ejecuta en Docker
QDRANT_URL=http://qdrant:6333
QDRANT_API_KEY=

# ============================================
# ALMACENAMIENTO (Storage)
# ============================================
# Opción 1: MinIO (S3 compatible local)
STORAGE_PROVIDER=minio
MINIO_ENDPOINT=http://minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=absa-lms
MINIO_USE_SSL=false

# Opción 2: Sistema de archivos local
# STORAGE_PROVIDER=local
# LOCAL_STORAGE_PATH=/app/storage

# Opción 3: AWS S3 (si prefieres)
# STORAGE_PROVIDER=s3
# AWS_ACCESS_KEY_ID=your_aws_key
# AWS_SECRET_ACCESS_KEY=your_aws_secret
# AWS_REGION=us-east-1
# AWS_S3_BUCKET=absa-lms

# ============================================
# EMAIL (Para códigos de verificación)
# ============================================
# Opción 1: Mailhog (desarrollo local)
EMAIL_PROVIDER=mailhog
MAILHOG_SMTP_HOST=mailhog
MAILHOG_SMTP_PORT=1025
MAILHOG_FROM_EMAIL=noreply@university.grupoabsa.ai

# Opción 2: SMTP genérico
# EMAIL_PROVIDER=smtp
# SMTP_HOST=tu-servidor-smtp.com
# SMTP_PORT=587
# SMTP_USER=tu-usuario
# SMTP_PASSWORD=tu-contraseña
# SMTP_FROM_EMAIL=noreply@university.grupoabsa.ai

# Opción 3: SendGrid
# EMAIL_PROVIDER=sendgrid
# SENDGRID_API_KEY=your_sendgrid_api_key
# SENDGRID_FROM_EMAIL=noreply@university.grupoabsa.ai

# ============================================
# NOTIFICACIONES (Opcional)
# ============================================
# Deshabilitado por defecto en self-hosted
NOTIFICATIONS_ENABLED=false

# ============================================
# ANALYTICS (Opcional)
# ============================================
# Opción 1: Plausible Analytics (self-hosted)
# ANALYTICS_PROVIDER=plausible
# PLAUSIBLE_DOMAIN=university.grupoabsa.ai
# PLAUSIBLE_API_KEY=your_plausible_api_key

# Opción 2: Matomo (self-hosted)
# ANALYTICS_PROVIDER=matomo
# MATOMO_URL=http://matomo:80
# MATOMO_SITE_ID=1

# Opción 3: Deshabilitado
VITE_ANALYTICS_ENDPOINT=
VITE_ANALYTICS_WEBSITE_ID=

# ============================================
# CONFIGURACIÓN AVANZADA
# ============================================

# Timeout para LLM (en segundos)
LLM_TIMEOUT=120

# Máximo tamaño de archivo para upload (en MB)
MAX_FILE_SIZE=100

# Máximo tamaño de chunk para embeddings
MAX_CHUNK_SIZE=1000

# Número de workers para procesamiento
WORKER_THREADS=4

# ============================================
# NOTAS IMPORTANTES
# ============================================
# 1. Todos los servicios se ejecutan en Docker
# 2. No hay dependencias externas de Manus
# 3. Puedes usar Ollama local para LLM (más rápido que OpenAI)
# 4. MinIO proporciona S3 compatible localmente
# 5. Mailhog es para desarrollo; usa SMTP real en producción
# 6. Qdrant es obligatorio para RAG
